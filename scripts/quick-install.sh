#!/bin/bash
# ============================================================================
# LingKong AI - Quick Installer (ä½¿ç”¨ llama.cpp)
# ============================================================================
# ä½ çš„ AI. ä½ çš„æ•°æ®. ä½ çš„æŒæ§.
#
# ä½¿ç”¨æ–¹æ³•:
#   curl -fsSL https://lingkong.xyz/install.sh | bash
# ============================================================================

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# é…ç½®
INSTALL_DIR="${LINGKONG_HOME:-$HOME/.lingkong}"
MODELS_DIR="${INSTALL_DIR}/models"
BIN_DIR="${INSTALL_DIR}/bin"
HF_BASE_URL="https://huggingface.co/jiaqiwang969/gemma3n-gguf/resolve/main"

# æ¨¡å‹åˆ—è¡¨
declare -A MODELS
MODELS["text"]="gemma-3n-E2B-it-Q4_K_M.gguf|2.8GB|ä¸»æ–‡æœ¬æ¨¡å‹ (æ¨è)"
MODELS["vision"]="gemma-3n-vision-mmproj-f16.gguf|600MB|è§†è§‰ç†è§£æ¨¡å—"
MODELS["audio"]="gemma-3n-audio-mmproj-f16.gguf|1.4GB|éŸ³é¢‘ç†è§£æ¨¡å—"

# ============================================================================
print_banner() {
    echo ""
    echo -e "${PURPLE}${BOLD}"
    echo "  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "  â•‘                                                           â•‘"
    echo "  â•‘   ğŸ‰  çµç©º AI  -  LingKong AI                             â•‘"
    echo "  â•‘                                                           â•‘"
    echo "  â•‘   ä½ çš„ AI. ä½ çš„æ•°æ®. ä½ çš„æŒæ§.                            â•‘"
    echo "  â•‘                                                           â•‘"
    echo "  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${NC}"
}

log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[âœ“]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[!]${NC} $1"; }
log_error() { echo -e "${RED}[âœ—]${NC} $1"; }
log_step() { echo -e "\n${CYAN}${BOLD}â–¶ $1${NC}"; }

# æ£€æµ‹ç³»ç»Ÿ
detect_platform() {
    local os=$(uname -s | tr '[:upper:]' '[:lower:]')
    local arch=$(uname -m)

    case "$os" in
        darwin) OS="macos" ;;
        linux) OS="linux" ;;
        *) log_error "ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: $os"; exit 1 ;;
    esac

    case "$arch" in
        x86_64|amd64) ARCH="x86_64" ;;
        arm64|aarch64) ARCH="arm64" ;;
        *) log_error "ä¸æ”¯æŒçš„æ¶æ„: $arch"; exit 1 ;;
    esac

    PLATFORM="${OS}-${ARCH}"
    log_info "æ£€æµ‹åˆ°ç³»ç»Ÿ: $PLATFORM"
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    log_step "æ£€æŸ¥ç³»ç»Ÿä¾èµ–"

    # æ£€æŸ¥ä¸‹è½½å·¥å…·
    if command -v curl &> /dev/null; then
        DOWNLOAD_CMD="curl -fSL --progress-bar"
    elif command -v wget &> /dev/null; then
        DOWNLOAD_CMD="wget --show-progress -qO-"
    else
        log_error "éœ€è¦ curl æˆ– wget"
        exit 1
    fi

    log_success "ä¾èµ–æ£€æŸ¥é€šè¿‡"
}

# åˆ›å»ºç›®å½•
create_directories() {
    log_step "åˆ›å»ºå®‰è£…ç›®å½•"
    mkdir -p "$MODELS_DIR"
    mkdir -p "$BIN_DIR"
    mkdir -p "$INSTALL_DIR/config"
    log_success "ç›®å½•åˆ›å»ºå®Œæˆ: $INSTALL_DIR"
}

# å®‰è£… llama.cpp (ä½¿ç”¨ Homebrew æˆ–é¢„ç¼–è¯‘)
install_llama_cpp() {
    log_step "å®‰è£… llama.cpp æ¨ç†å¼•æ“"

    if command -v llama-server &> /dev/null; then
        log_info "llama.cpp å·²å®‰è£…"
        return 0
    fi

    if [[ "$OS" == "macos" ]]; then
        if command -v brew &> /dev/null; then
            log_info "ä½¿ç”¨ Homebrew å®‰è£… llama.cpp..."
            brew install llama.cpp
            log_success "llama.cpp å®‰è£…å®Œæˆ"
            return 0
        fi
    fi

    # ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬
    log_info "ä¸‹è½½é¢„ç¼–è¯‘çš„ llama.cpp..."
    local llama_url="https://github.com/ggerganov/llama.cpp/releases/latest/download/llama-bin-${PLATFORM}.zip"

    if [[ "$PLATFORM" == "macos-arm64" ]]; then
        llama_url="https://github.com/ggerganov/llama.cpp/releases/latest/download/llama-bin-macos-arm64.zip"
    elif [[ "$PLATFORM" == "macos-x86_64" ]]; then
        llama_url="https://github.com/ggerganov/llama.cpp/releases/latest/download/llama-bin-macos-x64.zip"
    elif [[ "$PLATFORM" == "linux-x86_64" ]]; then
        llama_url="https://github.com/ggerganov/llama.cpp/releases/latest/download/llama-bin-ubuntu-x64.zip"
    fi

    local tmp_dir=$(mktemp -d)
    $DOWNLOAD_CMD "$llama_url" -o "$tmp_dir/llama.zip" || {
        log_warning "æ— æ³•ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬ï¼Œè¯·æ‰‹åŠ¨å®‰è£… llama.cpp"
        log_info "macOS: brew install llama.cpp"
        log_info "Linux: ä» https://github.com/ggerganov/llama.cpp ä¸‹è½½"
        return 1
    }

    unzip -q "$tmp_dir/llama.zip" -d "$tmp_dir"
    cp "$tmp_dir"/*/llama-server "$BIN_DIR/" 2>/dev/null || cp "$tmp_dir"/llama-server "$BIN_DIR/" 2>/dev/null
    chmod +x "$BIN_DIR/llama-server"
    rm -rf "$tmp_dir"

    log_success "llama.cpp å®‰è£…å®Œæˆ"
}

# ä¸‹è½½æ¨¡å‹
download_model() {
    local model_key="$1"
    local model_info="${MODELS[$model_key]}"
    local model_file=$(echo "$model_info" | cut -d'|' -f1)
    local model_size=$(echo "$model_info" | cut -d'|' -f2)
    local model_desc=$(echo "$model_info" | cut -d'|' -f3)

    local model_path="${MODELS_DIR}/${model_file}"

    if [[ -f "$model_path" ]]; then
        log_info "æ¨¡å‹å·²å­˜åœ¨: $model_file"
        return 0
    fi

    log_step "ä¸‹è½½æ¨¡å‹: $model_desc ($model_size)"
    local model_url="${HF_BASE_URL}/${model_file}"

    log_info "ä¸‹è½½åœ°å€: $model_url"
    log_warning "æ–‡ä»¶è¾ƒå¤§ ($model_size)ï¼Œè¯·è€å¿ƒç­‰å¾…..."

    $DOWNLOAD_CMD "$model_url" -o "$model_path" || {
        log_error "ä¸‹è½½å¤±è´¥: $model_file"
        return 1
    }

    log_success "æ¨¡å‹ä¸‹è½½å®Œæˆ: $model_file"
}

# åˆ›å»ºå¯åŠ¨è„šæœ¬
create_start_script() {
    log_step "åˆ›å»ºå¯åŠ¨è„šæœ¬"

    local start_script="${BIN_DIR}/lingkong-start"
    cat > "$start_script" << 'SCRIPT'
#!/bin/bash
# LingKong AI å¯åŠ¨è„šæœ¬

LINGKONG_HOME="${LINGKONG_HOME:-$HOME/.lingkong}"
MODEL="${1:-$LINGKONG_HOME/models/gemma-3n-E2B-it-Q4_K_M.gguf}"
PORT="${LINGKONG_PORT:-5001}"

# æ£€æŸ¥æ¨¡å‹
if [[ ! -f "$MODEL" ]]; then
    echo "é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: $MODEL"
    echo "è¯·å…ˆè¿è¡Œ: lingkong-download"
    exit 1
fi

# æ£€æŸ¥ llama-server
LLAMA_SERVER=""
if command -v llama-server &> /dev/null; then
    LLAMA_SERVER="llama-server"
elif [[ -f "$LINGKONG_HOME/bin/llama-server" ]]; then
    LLAMA_SERVER="$LINGKONG_HOME/bin/llama-server"
else
    echo "é”™è¯¯: æ‰¾ä¸åˆ° llama-server"
    echo "è¯·å®‰è£…: brew install llama.cpp"
    exit 1
fi

echo "ğŸ‰ å¯åŠ¨ çµç©º AI..."
echo "   æ¨¡å‹: $MODEL"
echo "   ç«¯å£: $PORT"
echo ""
echo "è®¿é—®åœ°å€: http://localhost:$PORT"
echo "æŒ‰ Ctrl+C åœæ­¢æœåŠ¡"
echo ""

$LLAMA_SERVER \
    --model "$MODEL" \
    --port "$PORT" \
    --host 0.0.0.0 \
    --ctx-size 8192 \
    --n-gpu-layers 99 \
    --flash-attn
SCRIPT
    chmod +x "$start_script"

    # åˆ›å»ºä¸‹è½½è„šæœ¬
    local download_script="${BIN_DIR}/lingkong-download"
    cat > "$download_script" << DLSCRIPT
#!/bin/bash
# LingKong AI æ¨¡å‹ä¸‹è½½è„šæœ¬

LINGKONG_HOME="\${LINGKONG_HOME:-\$HOME/.lingkong}"
HF_URL="https://huggingface.co/jiaqiwang969/gemma3n-gguf/resolve/main"

echo "ğŸ‰ çµç©º AI æ¨¡å‹ä¸‹è½½"
echo ""

download_model() {
    local name="\$1"
    local size="\$2"
    local path="\$LINGKONG_HOME/models/\$name"

    if [[ -f "\$path" ]]; then
        echo "âœ“ \$name å·²å­˜åœ¨"
        return 0
    fi

    echo "ä¸‹è½½ \$name (\$size)..."
    curl -fSL --progress-bar "\$HF_URL/\$name" -o "\$path"
    echo "âœ“ \$name ä¸‹è½½å®Œæˆ"
}

mkdir -p "\$LINGKONG_HOME/models"

case "\${1:-text}" in
    text|main)
        download_model "gemma-3n-E2B-it-Q4_K_M.gguf" "2.8GB"
        ;;
    vision)
        download_model "gemma-3n-vision-mmproj-f16.gguf" "600MB"
        ;;
    audio)
        download_model "gemma-3n-audio-mmproj-f16.gguf" "1.4GB"
        ;;
    all)
        download_model "gemma-3n-E2B-it-Q4_K_M.gguf" "2.8GB"
        download_model "gemma-3n-vision-mmproj-f16.gguf" "600MB"
        download_model "gemma-3n-audio-mmproj-f16.gguf" "1.4GB"
        ;;
    *)
        echo "ç”¨æ³•: lingkong-download [text|vision|audio|all]"
        ;;
esac

echo ""
echo "æ¨¡å‹å­˜æ”¾ä½ç½®: \$LINGKONG_HOME/models/"
DLSCRIPT
    chmod +x "$download_script"

    log_success "å¯åŠ¨è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# é…ç½® PATH
setup_path() {
    log_step "é…ç½®ç¯å¢ƒå˜é‡"

    local path_export="export PATH=\"\$PATH:${BIN_DIR}\""
    local home_export="export LINGKONG_HOME=\"${INSTALL_DIR}\""
    local shell_rc=""

    if [[ -f "$HOME/.zshrc" ]]; then
        shell_rc="$HOME/.zshrc"
    elif [[ -f "$HOME/.bashrc" ]]; then
        shell_rc="$HOME/.bashrc"
    elif [[ -f "$HOME/.profile" ]]; then
        shell_rc="$HOME/.profile"
    fi

    if [[ -n "$shell_rc" ]]; then
        if ! grep -q "LINGKONG_HOME" "$shell_rc" 2>/dev/null; then
            echo "" >> "$shell_rc"
            echo "# LingKong AI" >> "$shell_rc"
            echo "$home_export" >> "$shell_rc"
            echo "$path_export" >> "$shell_rc"
            log_success "å·²æ·»åŠ åˆ° $shell_rc"
        else
            log_info "ç¯å¢ƒå˜é‡å·²é…ç½®"
        fi
    fi

    export LINGKONG_HOME="$INSTALL_DIR"
    export PATH="$PATH:$BIN_DIR"
}

# æ‰“å°æˆåŠŸä¿¡æ¯
print_success() {
    echo ""
    echo -e "${GREEN}${BOLD}"
    echo "  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "  â•‘                                                           â•‘"
    echo "  â•‘   âœ…  å®‰è£…å®Œæˆï¼                                          â•‘"
    echo "  â•‘                                                           â•‘"
    echo "  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${NC}"
    echo ""
    echo -e "  ${BOLD}å¿«é€Ÿå¼€å§‹:${NC}"
    echo ""
    echo -e "    ${CYAN}1. é‡æ–°åŠ è½½ shell:${NC}"
    echo -e "       source ~/.zshrc  ${YELLOW}# æˆ– ~/.bashrc${NC}"
    echo ""
    echo -e "    ${CYAN}2. ä¸‹è½½æ¨¡å‹:${NC}"
    echo -e "       lingkong-download        # ä¸‹è½½ä¸»æ¨¡å‹ (2.8GB)"
    echo -e "       lingkong-download all    # ä¸‹è½½å…¨éƒ¨æ¨¡å‹ (5GB)"
    echo ""
    echo -e "    ${CYAN}3. å¯åŠ¨æœåŠ¡:${NC}"
    echo -e "       lingkong-start"
    echo ""
    echo -e "    ${CYAN}4. è®¿é—®:${NC}"
    echo -e "       http://localhost:5001"
    echo ""
    echo -e "  ${BOLD}æ–‡æ¡£:${NC} https://lingkong.xyz/docs"
    echo -e "  ${BOLD}GitHub:${NC} https://github.com/jiaqiwang969/gemma"
    echo ""
}

# ä¸»ç¨‹åº
main() {
    print_banner
    detect_platform
    check_dependencies
    create_directories
    install_llama_cpp
    create_start_script
    setup_path

    # è¯¢é—®æ˜¯å¦ä¸‹è½½æ¨¡å‹
    echo ""
    read -p "æ˜¯å¦ç°åœ¨ä¸‹è½½ä¸»æ¨¡å‹ (2.8GB)? [Y/n] " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]] || [[ -z $REPLY ]]; then
        download_model "text"
    fi

    print_success
}

main "$@"
