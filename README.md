<p align="center">
  <img src="https://img.shields.io/badge/ğŸ‰-çµç©º_AI-6366f1?style=for-the-badge" alt="LingKong AI">
</p>

<h1 align="center">çµç©º AI</h1>

<p align="center">
  <strong>ä½ çš„ AI. ä½ çš„æ•°æ®. ä½ çš„æŒæ§.</strong>
</p>

<p align="center">
  ä¸€ä¸ªå¼€æºçš„æœ¬åœ°å¤šæ¨¡æ€ AI å¹³å°ï¼Œè®©ä½ åœ¨è‡ªå·±çš„è®¾å¤‡ä¸Šè¿è¡Œå¼ºå¤§çš„ AIï¼Œæ— éœ€å°†æ•°æ®å‘é€åˆ°ä»»ä½•äº‘ç«¯ã€‚
</p>

<p align="center">
  <a href="https://github.com/jiaqiwang969/gemma/actions"><img src="https://github.com/jiaqiwang969/gemma/workflows/CI/badge.svg" alt="CI"></a>
  <a href="https://github.com/jiaqiwang969/gemma/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License"></a>
  <a href="http://115.159.223.227"><img src="https://img.shields.io/badge/demo-live-brightgreen.svg" alt="Demo"></a>
</p>

<p align="center">
  <a href="#-å¿«é€Ÿå¼€å§‹">å¿«é€Ÿå¼€å§‹</a> â€¢
  <a href="#-æ ¸å¿ƒç‰¹æ€§">æ ¸å¿ƒç‰¹æ€§</a> â€¢
  <a href="#-åœ¨çº¿æ¼”ç¤º">åœ¨çº¿æ¼”ç¤º</a> â€¢
  <a href="#-æ–‡æ¡£">æ–‡æ¡£</a> â€¢
  <a href="#-å•†ä¸šè®¡åˆ’ä¹¦">å•†ä¸šè®¡åˆ’ä¹¦</a>
</p>

---

## ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©çµç©º AIï¼Ÿ

| ç‰¹æ€§ | äº‘ç«¯ AI | çµç©º AI |
|------|---------|---------|
| **éšç§** | âŒ æœåŠ¡å•†èƒ½çœ‹åˆ°ä¸€åˆ‡ | âœ… 100% æœ¬åœ°ï¼Œå®Œå…¨ç§å¯† |
| **æˆæœ¬** | âŒ æŒ‰ Token æŒç»­ä»˜è´¹ | âœ… æ°¸ä¹…å…è´¹ (ä»…ç¡¬ä»¶æˆæœ¬) |
| **é€Ÿåº¦** | âŒ å—ç½‘ç»œå»¶è¿Ÿå½±å“ | âœ… å³æ—¶æœ¬åœ°å“åº” |
| **ç¦»çº¿** | âŒ å¿…é¡»è”ç½‘ | âœ… éšå¤„å¯ç”¨ |
| **æ§åˆ¶** | âŒ æ¡æ¬¾éšæ—¶å˜æ›´ | âœ… ä½ æ‹¥æœ‰å®Œå…¨æŒæ§ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šä»æºç ç¼–è¯‘ (æ¨è)

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/jiaqiwang969/gemma.git
cd gemma

# 2. å®‰è£… Python ä¾èµ–
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. å¯åŠ¨ WebUI æœåŠ¡å™¨
python apps/webui/server.py
# è®¿é—® http://localhost:5000
```

### æ–¹å¼äºŒï¼šä½¿ç”¨ LingKong CLI (Rust)

```bash
# 1. ç¼–è¯‘ CLI å·¥å…·
cd ../LingKong-AI/src
cargo build --release

# 2. å®‰è£…åˆ°ç³»ç»Ÿè·¯å¾„
cp target/release/lingkong ~/.local/bin/
export PATH="$HOME/.local/bin:$PATH"

# 3. åˆå§‹åŒ–ç¯å¢ƒ (ä¸‹è½½ llama.cpp, åˆ›å»ºç›®å½•)
lingkong install

# 4. ä¸‹è½½æ¨¡å‹
lingkong model pull gemma3n-2b-text

# 5. å¯åŠ¨æœåŠ¡
lingkong serve start
```

### æ–¹å¼ä¸‰ï¼šä¸€é”®éƒ¨ç½²åˆ°æœåŠ¡å™¨

```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šæ‰§è¡Œ
ssh ubuntu@your-server 'bash -s' < apps/deploy_all.sh

# ä¸Šä¼ ä»£ç 
scp apps/webui/server_lite.py ubuntu@your-server:/opt/lingkong-webui/server.py
scp -r apps/webui/static/* ubuntu@your-server:/opt/lingkong-webui/static/

# å¯åŠ¨æœåŠ¡
ssh ubuntu@your-server 'sudo systemctl enable --now lingkong-webui'
```

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ” å®Œå…¨ç§å¯†
- æ•°æ®æ°¸ä¸ç¦»å¼€ä½ çš„è®¾å¤‡
- æ— éœ€è´¦å·ã€æ— éœ€ç™»å½•
- é›¶çŸ¥è¯†æ¶æ„è®¾è®¡

### ğŸ¯ å¤šæ¨¡æ€èƒ½åŠ›
- **æ–‡æœ¬ç†è§£**: å¯¹è¯ã€å†™ä½œã€ç¼–ç¨‹
- **å›¾åƒç†è§£**: æè¿°ã€åˆ†æã€OCR
- **éŸ³é¢‘ç†è§£**: è½¬å½•ã€ç¿»è¯‘ã€æ€»ç»“

### âš¡ é«˜æ€§èƒ½æ¨ç†
- llama.cpp å¼•æ“ (Metal/CUDA åŠ é€Ÿ)
- ~94 tokens/s (M4 Max)
- æ”¯æŒ GGUF é‡åŒ–æ¨¡å‹

### ğŸ”Œ API å…¼å®¹
- å…¼å®¹ Google Gemini API
- æ— ç¼æ›¿æ¢ç°æœ‰åº”ç”¨
- æ”¯æŒæµå¼è¾“å‡º

## ğŸŒ åœ¨çº¿æ¼”ç¤º

è®¿é—®æˆ‘ä»¬çš„åœ¨çº¿æ¼”ç¤ºç«™ç‚¹ï¼š

| é¡µé¢ | åœ°å€ | è¯´æ˜ |
|------|------|------|
| ğŸ  é¡¹ç›®ä¸»é¡µ | http://115.159.223.227 | åŠŸèƒ½ä»‹ç»ã€å¿«é€Ÿå¼€å§‹ |
| ğŸ’¬ èŠå¤©ç•Œé¢ | http://115.159.223.227/static/index.html | å¤šæ¨¡æ€å¯¹è¯ä½“éªŒ |
| ğŸ“š API æ–‡æ¡£ | http://115.159.223.227/static/docs.html | Gemini å…¼å®¹ API |
| ğŸ“Š å•†ä¸šè®¡åˆ’ä¹¦ | http://115.159.223.227/static/pitch.html | æ„¿æ™¯ä¸å•†ä¸šæ¨¡å¼ |

## ğŸ“ é¡¹ç›®ç»“æ„

```
gemma/
â”œâ”€â”€ apps/                          # åº”ç”¨å±‚
â”‚   â”œâ”€â”€ webui/                     # Web èŠå¤©ç•Œé¢
â”‚   â”‚   â”œâ”€â”€ server.py              # Flask æœåŠ¡å™¨ (å®Œæ•´ç‰ˆ)
â”‚   â”‚   â”œâ”€â”€ server_lite.py         # Flask æœåŠ¡å™¨ (è½»é‡éƒ¨ç½²ç‰ˆ)
â”‚   â”‚   â”œâ”€â”€ static/                # å‰ç«¯é¡µé¢
â”‚   â”‚   â”‚   â”œâ”€â”€ home.html          # é¡¹ç›®ä¸»é¡µ
â”‚   â”‚   â”‚   â”œâ”€â”€ index.html         # èŠå¤©ç•Œé¢
â”‚   â”‚   â”‚   â”œâ”€â”€ docs.html          # API æ–‡æ¡£
â”‚   â”‚   â”‚   â””â”€â”€ pitch.html         # å•†ä¸šè®¡åˆ’ä¹¦
â”‚   â”‚   â””â”€â”€ deploy/                # éƒ¨ç½²è„šæœ¬
â”‚   â”œâ”€â”€ gemini_api/                # Gemini å…¼å®¹ API Gateway
â”‚   â””â”€â”€ examples/                  # ç¤ºä¾‹è„šæœ¬
â”œâ”€â”€ contexts/                      # é¢†åŸŸä¸Šä¸‹æ–‡
â”‚   â””â”€â”€ training/                  # è®­ç»ƒç›¸å…³
â”‚       â””â”€â”€ scripts/               # å¾®è°ƒè„šæœ¬
â”œâ”€â”€ experiments/                   # å®éªŒä»£ç 
â”‚   â”œâ”€â”€ vision/                    # å›¾åƒç†è§£å®éªŒ
â”‚   â””â”€â”€ audio/                     # éŸ³é¢‘ç†è§£å®éªŒ
â”œâ”€â”€ infra/                         # åŸºç¡€è®¾æ–½
â”‚   â””â”€â”€ llama.cpp/                 # æ¨ç†å¼•æ“ (å­æ¨¡å—)
â”œâ”€â”€ artifacts/                     # äº§ç‰©è¾“å‡º
â”‚   â”œâ”€â”€ gguf/                      # GGUF æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ lora/                      # LoRA é€‚é…å™¨
â”‚   â””â”€â”€ merged_model/              # åˆå¹¶åçš„æ¨¡å‹
â”œâ”€â”€ assets/                        # èµ„æºæ–‡ä»¶
â”‚   â””â”€â”€ data/                      # è®­ç»ƒæ•°æ®
â”œâ”€â”€ docs/                          # æ–‡æ¡£
â”‚   â””â”€â”€ å•†ä¸šè®¡åˆ’ä¹¦/                # å•†ä¸šè®¡åˆ’ä¹¦ PDF
â””â”€â”€ scripts/                       # å·¥å…·è„šæœ¬
```

## ğŸ› ï¸ LingKong CLI å‘½ä»¤

LingKong CLI æ˜¯ç”¨ Rust ç¼–å†™çš„å‘½ä»¤è¡Œå·¥å…·ï¼š

```bash
# ç¯å¢ƒæ£€æŸ¥
lingkong doctor                    # è¯Šæ–­ç³»ç»Ÿç¯å¢ƒ

# æ¨¡å‹ç®¡ç†
lingkong model list                # åˆ—å‡ºå¯ç”¨æ¨¡å‹
lingkong model pull <name>         # ä¸‹è½½æ¨¡å‹
lingkong model info <name>         # æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
lingkong model remove <name>       # åˆ é™¤æ¨¡å‹
lingkong model link /path/to.gguf  # é“¾æ¥æœ¬åœ°æ¨¡å‹

# æœåŠ¡ç®¡ç†
lingkong serve start               # å¯åŠ¨æœåŠ¡
lingkong serve start --model <n>   # æŒ‡å®šæ¨¡å‹å¯åŠ¨
lingkong serve stop                # åœæ­¢æœåŠ¡
lingkong serve status              # æŸ¥çœ‹çŠ¶æ€

# é…ç½®ç®¡ç†
lingkong config show               # æ˜¾ç¤ºé…ç½®
lingkong config edit               # ç¼–è¾‘é…ç½®
```

## ğŸ® ä½¿ç”¨ç¤ºä¾‹

### Python API è°ƒç”¨

```python
import requests

# æ–‡æœ¬ç”Ÿæˆ
response = requests.post(
    "http://localhost:5001/v1beta/models/gemma-3-pro-preview:generateContent",
    json={
        "contents": [{"parts": [{"text": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}]}]
    }
)
print(response.json()["candidates"][0]["content"]["parts"][0]["text"])
```

### å¤šæ¨¡æ€ç¤ºä¾‹

```python
from transformers import AutoProcessor, Gemma3nForConditionalGeneration
from PIL import Image
import torch

model = Gemma3nForConditionalGeneration.from_pretrained(
    "google/gemma-3n-E2B-it",
    device_map="auto",
    torch_dtype=torch.bfloat16,
)
processor = AutoProcessor.from_pretrained("google/gemma-3n-E2B-it")

# å›¾åƒç†è§£
image = Image.open("your_image.jpg")
messages = [{"role": "user", "content": [
    {"type": "image", "image": image},
    {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡"}
]}]

inputs = processor.apply_chat_template(messages, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=256)
print(processor.decode(outputs[0], skip_special_tokens=True))
```

### LoRA å¾®è°ƒ

```bash
# å‡†å¤‡è®­ç»ƒæ•°æ® (assets/data/train.jsonl)
{"messages": [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}

# è¿è¡Œå¾®è°ƒ
python contexts/training/scripts/finetune_lora.py

# æµ‹è¯•å¾®è°ƒæ•ˆæœ
python contexts/training/scripts/test_finetuned_model.py

# åˆå¹¶ LoRA æƒé‡
python contexts/training/scripts/merge_lora.py

# è½¬æ¢ä¸º GGUF
python infra/llama.cpp/convert_hf_to_gguf.py artifacts/merged_model \
    --outfile artifacts/gguf/model.gguf --outtype f16
```

## ğŸ’» ç¡¬ä»¶è¦æ±‚

| é…ç½® | è§„æ ¼ | é€‚ç”¨åœºæ™¯ | å‚è€ƒä»·æ ¼ |
|------|------|----------|----------|
| å…¥é—¨çº§ | Mac Mini M2 8GB | çº¯æ–‡æœ¬å¯¹è¯ | ~$600 |
| **æ¨è** | Mac Mini M4 24GB | å¤šæ¨¡æ€æ¨ç† | ~$1,200 |
| ä¸“ä¸šçº§ | Mac Studio / RTX 4090 | å¾®è°ƒè®­ç»ƒ | ~$4,000+ |

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | M4 Max 128GB |
|------|--------------|
| æ¨¡å‹åŠ è½½ | ~3.7 ç§’ |
| æ¨ç†é€Ÿåº¦ (PyTorch) | ~16 tokens/s |
| æ¨ç†é€Ÿåº¦ (llama.cpp) | ~94 tokens/s |
| LoRA å¾®è°ƒ | ~37 ç§’/epoch |

## ğŸ”§ å¼€å‘æŒ‡å—

### ç¼–è¯‘ LingKong CLI

```bash
cd ../LingKong-AI/src
cargo build --release
```

### è¿è¡Œæµ‹è¯•

```bash
# Python æµ‹è¯•
python -m pytest tests/

# Rust æµ‹è¯•
cd ../LingKong-AI/src
cargo test
```

### ä»£ç é£æ ¼

```bash
# Python
pip install black isort
black .
isort .

# Rust
cargo fmt
cargo clippy
```

## ğŸ“š æ–‡æ¡£

- [API æ–‡æ¡£](http://115.159.223.227/static/docs.html) - Gemini å…¼å®¹ API ä½¿ç”¨æŒ‡å—
- [éƒ¨ç½²æŒ‡å—](apps/webui/deploy/README.md) - æœåŠ¡å™¨éƒ¨ç½²è¯´æ˜
- [æ¶æ„è®¾è®¡](docs/architecture/README.md) - ç³»ç»Ÿæ¶æ„æ–‡æ¡£
- [å•†ä¸šè®¡åˆ’ä¹¦](http://115.159.223.227/static/pitch.html) - é¡¹ç›®æ„¿æ™¯ä¸å•†ä¸šæ¨¡å¼

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ”— é“¾æ¥

- **åœ¨çº¿æ¼”ç¤º**: http://115.159.223.227
- **GitHub**: https://github.com/jiaqiwang969/gemma
- **å•†ä¸šè®¡åˆ’ä¹¦**: http://115.159.223.227/static/pitch.html

---

<p align="center">
  <strong>çµç©º AI</strong> - ä½ çš„ AI. ä½ çš„æ•°æ®. ä½ çš„æŒæ§.
</p>
