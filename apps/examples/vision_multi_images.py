"""
ç¤ºä¾‹2b: å¤šå›¾æ‰¹é‡å¤„ç† - Gemma 3n å¯ä»¥ä¸€æ¬¡å¤„ç†å¤šå¼ å›¾ç‰‡

å…³äºå›¾ç‰‡æ•°é‡é™åˆ¶ï¼š
  - Gemma 3n æ²¡æœ‰ç¡¬æ€§çš„"æœ€å¤§å›¾ç‰‡æ•°é‡"é™åˆ¶
  - é™åˆ¶å–å†³äºæ€»ä½“ context token æ•°é‡
  - Gemma 3n ä¸Šä¸‹æ–‡é™åˆ¶: 32K tokens (è¾“å…¥ + è¾“å‡º)
  - æ¯å¼ å›¾ç‰‡å¤§çº¦å ç”¨ 256-512 tokensï¼ˆå–å†³äºåˆ†è¾¨ç‡ï¼‰
  - ç†è®ºä¸Šå¯ä»¥å¤„ç† 50+ å¼ å›¾ç‰‡ï¼Œä½†å®é™…å—å†…å­˜é™åˆ¶

æ”¯æŒï¼š
  1. å¤šå¼ å›¾ç‰‡ä½œä¸ºä¸€ä¸ªå¯¹è¯è¾“å…¥ï¼ˆæ¯”è¾ƒ/åˆ†æå¤šå¼ å›¾ï¼‰
  2. æ‰¹é‡ç‹¬ç«‹å¤„ç†å¤šå¼ å›¾ç‰‡
"""
import os
from pathlib import Path
import torch
from transformers import AutoProcessor, Gemma3nForConditionalGeneration
from PIL import Image
import time
import warnings
warnings.filterwarnings("ignore")

os.environ["PYTORCH_MPS_HIGH_WATERMARK_RATIO"] = "0.0"

# Gemma 3n ä¸Šä¸‹æ–‡é™åˆ¶
MAX_CONTEXT_TOKENS = 32768  # 32K tokens

print("=" * 60)
print("ç¤ºä¾‹2b: Gemma 3n å¤šå›¾æ‰¹é‡å¤„ç†")
print("=" * 60)
print(f"ä¸Šä¸‹æ–‡é™åˆ¶: {MAX_CONTEXT_TOKENS:,} tokens (32K)")
print("å›¾ç‰‡æ•°é‡: æ— ç¡¬æ€§é™åˆ¶ï¼Œå–å†³äºæ€» token æ•°")
print("=" * 60)

model_name = "google/gemma-3n-E2B-it"

print("\n[1] åŠ è½½æ¨¡å‹...")
processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)
model = Gemma3nForConditionalGeneration.from_pretrained(
    model_name,
    device_map="auto",
    max_memory={"mps": "64GiB", "cpu": "64GiB"},
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
)
model.eval()
print("    æ¨¡å‹åŠ è½½å®Œæˆ!")

# å›¾ç‰‡è·¯å¾„
ROOT_DIR = Path(__file__).resolve().parents[2]
DATA_DIR = ROOT_DIR / "assets" / "data" / "images"
IMAGE_FILES = ["cat.jpg", "dog.jpg", "food.jpg", "bee.jpg"]


def load_images(image_paths):
    """åŠ è½½å¤šå¼ å›¾ç‰‡"""
    images = []
    for path in image_paths:
        full_path = Path(path) if os.path.isabs(path) else DATA_DIR / path
        if full_path.exists():
            img = Image.open(full_path).convert("RGB")
            images.append((path, img))
            print(f"    å·²åŠ è½½: {path} ({img.size[0]}x{img.size[1]})")
        else:
            print(f"    è·³è¿‡: {path} (æ–‡ä»¶ä¸å­˜åœ¨)")
    return images


# ============================================================
# æ–¹æ³•1: å¤šå¼ å›¾ç‰‡åœ¨åŒä¸€ä¸ªå¯¹è¯ä¸­ï¼ˆç”¨äºæ¯”è¾ƒ/åˆ†æå¤šå¼ å›¾ï¼‰
# ============================================================
def analyze_multiple_images(images, question):
    """
    å°†å¤šå¼ å›¾ç‰‡æ”¾å…¥åŒä¸€ä¸ªå¯¹è¯ä¸­è¿›è¡Œåˆ†æ
    é€‚ç”¨äºï¼šæ¯”è¾ƒå›¾ç‰‡ã€æ‰¾ä¸åŒã€æè¿°å¤šä¸ªç‰©ä½“ç­‰
    """
    print(f"\n{'='*60}")
    print(f"å¤šå›¾è”åˆåˆ†æ ({len(images)} å¼ å›¾ç‰‡)")
    print(f"{'='*60}")
    print(f"é—®é¢˜: {question}")

    # æ„å»ºåŒ…å«å¤šå¼ å›¾ç‰‡çš„æ¶ˆæ¯
    content = []
    for name, img in images:
        content.append({"type": "image", "image": img})
    content.append({"type": "text", "text": question})

    messages = [{"role": "user", "content": content}]

    start_time = time.time()

    inputs = processor.apply_chat_template(
        messages,
        add_generation_prompt=True,
        tokenize=True,
        return_dict=True,
        return_tensors="pt"
    )

    input_ids = inputs["input_ids"].to(model.device)
    attention_mask = inputs["attention_mask"].to(model.device)
    pixel_values = inputs["pixel_values"].to(model.device, dtype=model.dtype)

    input_tokens = input_ids.shape[1]
    remaining_tokens = MAX_CONTEXT_TOKENS - input_tokens

    print(f"\nğŸ“Š Token ç»Ÿè®¡:")
    print(f"    è¾“å…¥ tokens: {input_tokens:,} / {MAX_CONTEXT_TOKENS:,} ({input_tokens/MAX_CONTEXT_TOKENS*100:.1f}%)")
    print(f"    å‰©ä½™ç©ºé—´: {remaining_tokens:,} tokens")
    print(f"    å›¾ç‰‡å¼ é‡: {pixel_values.shape}")

    max_new_tokens = min(500, remaining_tokens - 100)  # é¢„ç•™ä¸€äº›ç©ºé—´

    with torch.inference_mode():
        outputs = model.generate(
            input_ids=input_ids,
            attention_mask=attention_mask,
            pixel_values=pixel_values,
            max_new_tokens=max_new_tokens,
            do_sample=False,
        )

    elapsed = time.time() - start_time
    output_tokens = len(outputs[0]) - input_tokens
    total_tokens = input_tokens + output_tokens
    response = processor.tokenizer.decode(outputs[0][input_ids.shape[1]:], skip_special_tokens=True)

    print(f"\nå›ç­”:\n{'-'*40}")
    print(response)
    print(f"{'-'*40}")
    print(f"è¾“å‡º tokens: {output_tokens:,}")
    print(f"æ€»è®¡ tokens: {total_tokens:,} / {MAX_CONTEXT_TOKENS:,} ({total_tokens/MAX_CONTEXT_TOKENS*100:.1f}%)")
    print(f"è€—æ—¶: {elapsed:.2f}s")

    return response


# ============================================================
# æ–¹æ³•2: æ‰¹é‡ç‹¬ç«‹å¤„ç†æ¯å¼ å›¾ç‰‡
# ============================================================
def batch_process_images(images, question):
    """
    ç‹¬ç«‹å¤„ç†æ¯å¼ å›¾ç‰‡ï¼Œä½¿ç”¨ç›¸åŒçš„é—®é¢˜
    é€‚ç”¨äºï¼šæ‰¹é‡æè¿°ã€æ‰¹é‡åˆ†ç±»ç­‰
    """
    print(f"\n{'='*60}")
    print(f"æ‰¹é‡ç‹¬ç«‹å¤„ç† ({len(images)} å¼ å›¾ç‰‡)")
    print(f"{'='*60}")
    print(f"ç»Ÿä¸€é—®é¢˜: {question}")

    results = []
    total_start = time.time()

    for i, (name, img) in enumerate(images):
        print(f"\n[{i+1}/{len(images)}] å¤„ç†: {name}")

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": img},
                    {"type": "text", "text": question}
                ]
            }
        ]

        start_time = time.time()

        inputs = processor.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt"
        )

        input_ids = inputs["input_ids"].to(model.device)
        attention_mask = inputs["attention_mask"].to(model.device)
        pixel_values = inputs["pixel_values"].to(model.device, dtype=model.dtype)

        with torch.inference_mode():
            outputs = model.generate(
                input_ids=input_ids,
                attention_mask=attention_mask,
                pixel_values=pixel_values,
                max_new_tokens=200,
                do_sample=False,
            )

        elapsed = time.time() - start_time
        response = processor.tokenizer.decode(outputs[0][input_ids.shape[1]:], skip_special_tokens=True)

        results.append({
            "image": name,
            "response": response,
            "time": elapsed
        })

        print(f"    å›ç­”: {response[:100]}..." if len(response) > 100 else f"    å›ç­”: {response}")
        print(f"    è€—æ—¶: {elapsed:.2f}s")

    total_elapsed = time.time() - total_start
    print(f"\n{'='*60}")
    print(f"æ‰¹é‡å¤„ç†å®Œæˆ! æ€»è€—æ—¶: {total_elapsed:.2f}s")
    print(f"å¹³å‡æ¯å¼ : {total_elapsed/len(images):.2f}s")

    return results


# ============================================================
# ä¸»ç¨‹åº
# ============================================================
if __name__ == "__main__":
    print("\n[2] åŠ è½½æµ‹è¯•å›¾ç‰‡...")
    images = load_images(IMAGE_FILES)

    if len(images) < 2:
        print("é”™è¯¯: éœ€è¦è‡³å°‘2å¼ å›¾ç‰‡è¿›è¡Œæµ‹è¯•")
        exit(1)

    print(f"\næˆåŠŸåŠ è½½ {len(images)} å¼ å›¾ç‰‡")

    # æ¼”ç¤º1: å¤šå›¾è”åˆåˆ†æï¼ˆæ¯”è¾ƒä¸¤å¼ å›¾ï¼‰
    print("\n" + "=" * 60)
    print("æ¼”ç¤º1: æ¯”è¾ƒä¸¤å¼ å›¾ç‰‡ (cat.jpg vs dog.jpg)")
    print("=" * 60)

    two_images = [img for img in images if img[0] in ["cat.jpg", "dog.jpg"]]
    if len(two_images) == 2:
        analyze_multiple_images(
            two_images,
            "Compare these two images. What animals do you see? What are the similarities and differences between them?"
        )

    # æ¼”ç¤º2: å¤šå›¾è”åˆåˆ†æï¼ˆåˆ†ææ‰€æœ‰å›¾ç‰‡ï¼‰
    print("\n" + "=" * 60)
    print("æ¼”ç¤º2: åŒæ—¶åˆ†æå¤šå¼ å›¾ç‰‡")
    print("=" * 60)

    # åªç”¨å‰3å¼ å›¾é¿å…å†…å­˜é—®é¢˜
    subset = images[:3]
    analyze_multiple_images(
        subset,
        f"I'm showing you {len(subset)} images. Please describe each image briefly and tell me what they have in common."
    )

    # æ¼”ç¤º3: æ‰¹é‡ç‹¬ç«‹å¤„ç†
    print("\n" + "=" * 60)
    print("æ¼”ç¤º3: æ‰¹é‡ç‹¬ç«‹å¤„ç†æ¯å¼ å›¾ç‰‡")
    print("=" * 60)

    batch_process_images(
        images,
        "What is the main subject of this image? Answer in one sentence."
    )

    print("\n" + "=" * 60)
    print("æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)
